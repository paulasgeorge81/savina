{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMSG = 100_000\n",
    "# ITERATIONS = 20\n",
    "# # Load Scala benchmark data\n",
    "# scala_idle_raw_data = pd.read_csv('../data/ping_pong/1/ping_pong_akka_actor_benchmark_idle_power.csv')\n",
    "# scala_bench_raw_data = pd.read_csv('../data/ping_pong/1/ping_pong_akka_actor_benchmark_power_metrics.csv')\n",
    "\n",
    "# # Load Erlang benchmark data\n",
    "# erlang_idle_raw_data = pd.read_csv('../data/ping_pong/1/ping_pong_benchmark_idle_power.csv')\n",
    "# erlang_bench_raw_data = pd.read_csv('../data/ping_pong/1/ping_pong_benchmark_power_metrics.csv')\n",
    "\n",
    "# NMSG = 1_000_000\n",
    "# ITERATIONS = 10\n",
    "# # Load Scala benchmark data\n",
    "# scala_idle_raw_data = pd.read_csv('../data/ping_pong/2/ping_pong_akka_actor_benchmark_idle_power.csv')\n",
    "# scala_bench_raw_data = pd.read_csv('../data/ping_pong/2/ping_pong_akka_actor_benchmark_power_metrics.csv')\n",
    "\n",
    "# # Load Erlang benchmark data\n",
    "# erlang_idle_raw_data = pd.read_csv('../data/ping_pong/2/ping_pong_benchmark_idle_power.csv')\n",
    "# erlang_bench_raw_data = pd.read_csv('../data/ping_pong/2/ping_pong_benchmark_power_metrics.csv')\n",
    "\n",
    "NMSG = 10_000_000\n",
    "ITERATIONS = 10\n",
    "parent_dir = '../data/ping_pong/'\n",
    "# Load Scala benchmark data\n",
    "scala_idle_raw_data = pd.read_csv(f'{parent_dir}3/ping_pong_akka_actor_benchmark_idle_power.csv')\n",
    "scala_bench_raw_data = pd.read_csv(f'{parent_dir}3/ping_pong_akka_actor_benchmark_power_metrics.csv')\n",
    "\n",
    "# Load Erlang benchmark data\n",
    "erlang_idle_raw_data = pd.read_csv(f'{parent_dir}3/ping_pong_benchmark_idle_power.csv')\n",
    "erlang_bench_raw_data = pd.read_csv(f'{parent_dir}3/ping_pong_benchmark_power_metrics.csv')\n",
    "\n",
    "# Replace empty or missing values with \"N/A\" in non-numeric columns\n",
    "scala_idle_raw_data.fillna(\"N/A\", inplace=True)\n",
    "scala_bench_raw_data.fillna(\"N/A\", inplace=True)\n",
    "erlang_idle_raw_data.fillna(\"N/A\", inplace=True)\n",
    "erlang_bench_raw_data.fillna(\"N/A\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_message_count(nmsg):\n",
    "    \"\"\"Formats large numbers into shortened notation (e.g., 1B, 100M, 10M).\"\"\"\n",
    "    if nmsg >= 1_000_000_000:\n",
    "        return f\"{nmsg // 1_000_000_000}B\"\n",
    "    elif nmsg >= 1_000_000:\n",
    "        return f\"{nmsg // 1_000_000}M\"\n",
    "    elif nmsg >= 1_000:\n",
    "        return f\"{nmsg // 1_000}K\"\n",
    "    return str(nmsg)\n",
    "\n",
    "message_label = format_message_count(NMSG)\n",
    "title_config_prefix = f\"({message_label} Messages, {ITERATIONS} Iterations)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Raw Data:\")\n",
    "print(scala_idle_raw_data.shape)\n",
    "scala_idle_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Raw Data:\")\n",
    "print(scala_bench_raw_data.shape)\n",
    "scala_bench_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Raw Data:\")\n",
    "print(erlang_idle_raw_data.shape)\n",
    "erlang_idle_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Raw Data:\")\n",
    "print(erlang_bench_raw_data.shape)\n",
    "erlang_bench_raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df_copy = df.copy() \n",
    "\n",
    "    # Convert Timestamp to datetime format (extract date-time pattern)\n",
    "    df_copy['Timestamp'] = pd.to_datetime(\n",
    "        df['Timestamp'].str.extract(r'(\\w{3} \\w{3} \\d{1,2} \\d{2}:\\d{2}:\\d{2} \\d{4})')[0], \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Extract elapsed time in milliseconds\n",
    "    df_copy['Time Elapsed (ms)'] = pd.to_numeric(\n",
    "        df['Timestamp'].str.extract(r'\\((\\d+\\.\\d+)ms elapsed\\)')[0], \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Extract numeric temperature values\n",
    "    df_copy['CPU Temp(C)'] = df['CPU Temp(C)'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "    # Calculate Energy columns (Power * Time Elapsed)\n",
    "    power_columns = [\"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \"(CPUs+GT+SA) Power(W)\"]\n",
    "    for column in power_columns:\n",
    "        energy_column = column.replace('Power(W)', 'Energy(J)')\n",
    "        df_copy[energy_column] = df_copy[column] * df_copy['Time Elapsed (ms)'] / 1000  # Convert ms to seconds\n",
    "\n",
    "    # Fill N/A values with 0 for numerical columns\n",
    "    df_copy = df_copy.fillna(0)\n",
    "    # df_copy.fillna({col: 0 for col in df_copy.select_dtypes(include=['number']).columns}, inplace=True)\n",
    "\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_idle_clean_data = clean_data(scala_idle_raw_data)\n",
    "scala_bench_clean_data = clean_data(scala_bench_raw_data)\n",
    "erlang_idle_clean_data = clean_data(erlang_idle_raw_data)\n",
    "erlang_bench_clean_data = clean_data(erlang_bench_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Clean Data:\")\n",
    "print(scala_idle_clean_data.shape)\n",
    "scala_idle_clean_data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Clean Data:\")\n",
    "print(scala_bench_clean_data.shape)\n",
    "scala_bench_clean_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Clean Data:\")\n",
    "print(erlang_idle_clean_data.shape)\n",
    "erlang_idle_clean_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Clean Data:\")\n",
    "print(erlang_bench_clean_data.shape)\n",
    "erlang_bench_clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Removes outliers from the specified columns using the IQR method.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for column in columns:\n",
    "        Q1 = df_clean[column].quantile(0.25)\n",
    "        Q3 = df_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_removal_columns = [\n",
    "    \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "    \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "]\n",
    "\n",
    "scala_idle_data = remove_outliers(scala_idle_clean_data, outlier_removal_columns)\n",
    "scala_bench_data = remove_outliers(scala_bench_clean_data, outlier_removal_columns)\n",
    "erlang_idle_data = remove_outliers(erlang_idle_clean_data, outlier_removal_columns)\n",
    "erlang_bench_data = remove_outliers(erlang_bench_clean_data, outlier_removal_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Data: \")\n",
    "print(scala_idle_data.shape)\n",
    "scala_idle_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Data: \")\n",
    "print(scala_bench_data.shape)\n",
    "scala_bench_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Data: \")\n",
    "print(erlang_idle_data.shape)\n",
    "erlang_idle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Data: \")\n",
    "print(erlang_bench_data.shape)\n",
    "erlang_bench_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(idle_df, bench_df, title_prefix):\n",
    "    \"\"\"\n",
    "    Creates side-by-side subplots for each metric, plotting idle (left) and benchmark (right),\n",
    "    using elapsed time on the x-axis.\n",
    "    \"\"\"\n",
    "    columns_to_plot = [\n",
    "        \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "        \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "    ]\n",
    "    \n",
    "    # Set Seaborn theme\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "    # Compute elapsed time starting from t=0\n",
    "    idle_df = idle_df.copy()\n",
    "    bench_df = bench_df.copy()\n",
    "    \n",
    "    # idle_df[\"Elapsed Time (s)\"] = (idle_df[\"Timestamp\"] - idle_df[\"Timestamp\"].iloc[0]).dt.total_seconds()\n",
    "    # bench_df[\"Elapsed Time (s)\"] = (bench_df[\"Timestamp\"] - bench_df[\"Timestamp\"].iloc[0]).dt.total_seconds()\n",
    "\n",
    "    idle_df[\"Elapsed Time (s)\"] = (idle_df[\"Time Elapsed (ms)\"].cumsum() - idle_df[\"Time Elapsed (ms)\"].iloc[0]) / 1000\n",
    "    bench_df[\"Elapsed Time (s)\"] = (bench_df[\"Time Elapsed (ms)\"].cumsum() - bench_df[\"Time Elapsed (ms)\"].iloc[0]) / 1000\n",
    "\n",
    "    for column in columns_to_plot:\n",
    "        # Create side-by-side subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "        # Plot Idle data on the first subplot\n",
    "        sns.lineplot(data=idle_df, x=\"Elapsed Time (s)\", y=column, label=\"Idle\", color='blue', linestyle='--', ax=axes[0])\n",
    "        axes[0].set_title(f\"Idle - {column}\", fontsize=12)\n",
    "        axes[0].set_xlabel(\"Elapsed Time (s)\", fontsize=10)\n",
    "        axes[0].set_ylabel(column, fontsize=10)\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # Plot Benchmark data on the second subplot\n",
    "        sns.lineplot(data=bench_df, x=\"Elapsed Time (s)\", y=column, label=\"Benchmark\", color='red', ax=axes[1])\n",
    "        axes[1].set_title(f\"Benchmark - {column}\", fontsize=12)\n",
    "        axes[1].set_xlabel(\"Elapsed Time (s)\", fontsize=10)\n",
    "        axes[1].set_ylabel(column, fontsize=10)\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # Main figure title\n",
    "        fig.suptitle(f\"{title_prefix} - {column}\", fontsize=14)\n",
    "        \n",
    "        # Adjust layout to avoid overlap\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(scala_idle_data, scala_bench_data, \"Scala Benchmark - Idle vs Active\")\n",
    "plot_graphs(erlang_idle_data, erlang_bench_data, \"Erlang Benchmark - Idle vs Active\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_erlang_vs_scala(erlang_df, scala_df, idle_erlang_df, idle_scala_df, title_prefix):\n",
    "    \"\"\"\n",
    "    Plots Erlang and Scala benchmark data with elapsed time starting at t=0,\n",
    "    after subtracting corresponding idle values.\n",
    "    \"\"\"\n",
    "    columns_to_plot = [\n",
    "        \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "        \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "    ]\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "    # Normalize elapsed time to start from t=0\n",
    "    erlang_df = erlang_df.copy()\n",
    "    scala_df = scala_df.copy()\n",
    "\n",
    "    # erlang_df[\"Elapsed Time (s)\"] = (erlang_df[\"Timestamp\"] - erlang_df[\"Timestamp\"].iloc[0]).dt.total_seconds()\n",
    "    # scala_df[\"Elapsed Time (s)\"] = (scala_df[\"Timestamp\"] - scala_df[\"Timestamp\"].iloc[0]).dt.total_seconds()\n",
    "\n",
    "    erlang_df[\"Elapsed Time (s)\"] = (erlang_df[\"Time Elapsed (ms)\"].cumsum() - erlang_df[\"Time Elapsed (ms)\"].iloc[0]) / 1000\n",
    "    scala_df[\"Elapsed Time (s)\"] = (scala_df[\"Time Elapsed (ms)\"].cumsum() - scala_df[\"Time Elapsed (ms)\"].iloc[0]) / 1000\n",
    "\n",
    "\n",
    "    for column in columns_to_plot:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        # Subtract idle values\n",
    "        erlang_df[\"Adjusted \" + column] = np.maximum(0, erlang_df[column] - idle_erlang_df[column].mean())\n",
    "        scala_df[\"Adjusted \" + column] = np.maximum(0, scala_df[column] - idle_scala_df[column].mean())\n",
    "\n",
    "        # Plot Erlang benchmark\n",
    "        sns.lineplot(data=erlang_df, x=\"Elapsed Time (s)\", y=\"Adjusted \" + column, label=\"Erlang\", color='blue', ax=ax)\n",
    "\n",
    "        # Plot Scala benchmark\n",
    "        sns.lineplot(data=scala_df, x=\"Elapsed Time (s)\", y=\"Adjusted \" + column, label=\"Scala\", color='red', ax=ax)\n",
    "\n",
    "        # Graph formatting\n",
    "        ax.set_title(f\"{title_prefix} - {column}\", fontsize=14)\n",
    "        ax.set_xlabel(\"Elapsed Time (s)\", fontsize=12)\n",
    "        ax.set_ylabel(column, fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_erlang_vs_scala(erlang_bench_data, scala_bench_data, erlang_idle_data, scala_idle_data, f\"Eralng vs Scala Ping-Pong Benchmark {title_config_prefix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Average Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_columns = [\"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \"(CPUs+GT+SA) Power(W)\",\"CPU Temp(C)\", \"Avg Num Cores Active\", \"CPU Core Energy(J)\", \"GT Energy(J)\", \"DRAM Energy(J)\", \"(CPUs+GT+SA) Energy(J)\"]\n",
    "\n",
    "scala_idle_avgs = scala_idle_data[metrics_columns].mean()\n",
    "erlang_idle_avgs = erlang_idle_data[metrics_columns].mean()\n",
    "scala_bench_avgs = scala_bench_data[metrics_columns].mean()\n",
    "erlang_bench_avgs = erlang_bench_data[metrics_columns].mean()\n",
    "\n",
    "scala_net_avgs = scala_bench_avgs - scala_idle_avgs\n",
    "erlang_net_avgs = erlang_bench_avgs - erlang_idle_avgs\n",
    "\n",
    "\n",
    "print(\"Net Average Metrics Comparison:\\n\")\n",
    "print(\"Scala Benchmark:\")\n",
    "print(scala_net_avgs, \"\\n\")\n",
    "print(\"Erlang Benchmark:\")\n",
    "print(erlang_net_avgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
