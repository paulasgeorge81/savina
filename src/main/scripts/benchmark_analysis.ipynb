{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Scala benchmark data\n",
    "scala_idle_data = pd.read_csv('../data/20250309091438_ping_pong_akka_actor_benchmark_idle_power.csv')\n",
    "scala_bench_data = pd.read_csv('../data/20250309091449_ping_pong_akka_actor_benchmark_power_metrics.csv')\n",
    "\n",
    "# Load Erlang benchmark data\n",
    "erlang_idle_data = pd.read_csv('../data/20250309091714_ping_pong_benchmark_idle_power.csv')\n",
    "erlang_bench_data = pd.read_csv('../data/20250309091725_ping_pong_benchmark_power_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Data Sample:\")\n",
    "print(scala_idle_data.shape)\n",
    "scala_idle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Data Sample:\")\n",
    "print(scala_bench_data.shape)\n",
    "scala_bench_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Data Sample:\")\n",
    "print(erlang_idle_data.shape)\n",
    "erlang_idle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Data Sample:\")\n",
    "print(erlang_bench_data.shape)\n",
    "erlang_bench_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df_copy = df.copy() \n",
    "\n",
    "    # Convert Timestamp to datetime format (extract date-time pattern)\n",
    "    df_copy['Timestamp'] = pd.to_datetime(\n",
    "        df['Timestamp'].str.extract(r'(\\w{3} \\w{3} \\d{1,2} \\d{2}:\\d{2}:\\d{2} \\d{4})')[0], \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Extract elapsed time in milliseconds\n",
    "    df_copy['Time Elapsed (ms)'] = pd.to_numeric(\n",
    "        df['Timestamp'].str.extract(r'\\((\\d+\\.\\d+)ms elapsed\\)')[0], \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Extract numeric temperature values\n",
    "    df_copy['CPU Temp(C)'] = df['CPU Temp(C)'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "    # Calculate Energy columns (Power * Time Elapsed)\n",
    "    power_columns = [\"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \"(CPUs+GT+SA) Power(W)\"]\n",
    "    for column in power_columns:\n",
    "        energy_column = column.replace('Power(W)', 'Energy(J)')\n",
    "        df_copy[energy_column] = df_copy[column] * df_copy['Time Elapsed (ms)'] / 1000  # Convert ms to seconds\n",
    "\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_idle_data_clean = clean_data(scala_idle_data)\n",
    "scala_bench_data_clean = clean_data(scala_bench_data)\n",
    "erlang_idle_data_clean = clean_data(erlang_idle_data)\n",
    "erlang_bench_data_clean = clean_data(erlang_bench_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Cleaned Data Sample:\")\n",
    "print(scala_idle_data_clean.shape)\n",
    "scala_idle_data_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Cleaned Data Sample:\")\n",
    "print(scala_bench_data_clean.shape)\n",
    "scala_bench_data_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Cleaned Data Sample:\")\n",
    "print(erlang_idle_data_clean.shape)\n",
    "erlang_idle_data_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Cleaned Data Sample:\")\n",
    "print(erlang_bench_data_clean.shape)\n",
    "erlang_bench_data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Removes outliers from the specified columns using the IQR method.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for column in columns:\n",
    "        Q1 = df_clean[column].quantile(0.25)\n",
    "        Q3 = df_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of interest for outlier removal\n",
    "columns_of_interest = [\n",
    "    \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "    \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "]\n",
    "\n",
    "scala_idle_data_clean_outlier = remove_outliers(scala_idle_data_clean, columns_of_interest)\n",
    "scala_bench_data_clean_outlier = remove_outliers(scala_bench_data_clean, columns_of_interest)\n",
    "erlang_idle_data_clean_outlier = remove_outliers(erlang_idle_data_clean, columns_of_interest)\n",
    "erlang_bench_data_clean_outlier = remove_outliers(erlang_bench_data_clean, columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Idle Cleaned Data After Outlier Removal: \")\n",
    "print(scala_idle_data_clean_outlier.shape)\n",
    "scala_idle_data_clean_outlier.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scala Benchmark Cleaned Data After Outlier Removal: \")\n",
    "print(scala_bench_data_clean_outlier.shape)\n",
    "scala_bench_data_clean_outlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Idle Cleaned Data After Outlier Removal: \")\n",
    "print(erlang_idle_data_clean_outlier.shape)\n",
    "erlang_idle_data_clean_outlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erlang Benchmark Cleaned Data After Outlier Removal: \")\n",
    "print(erlang_bench_data_clean_outlier.shape)\n",
    "erlang_bench_data_clean_outlier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_graphs(idle_df, bench_df, title_prefix):\n",
    "#     \"\"\"\n",
    "#     Creates separate figures for each metric, plotting idle (left) and benchmark (right).\n",
    "#     \"\"\"\n",
    "#     columns_to_plot = [\n",
    "#         \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "#         \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "#     ]\n",
    "    \n",
    "#     for column in columns_to_plot:\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "#         # Idle (Left Side)\n",
    "#         axes[0].plot(idle_df[\"Timestamp\"], idle_df[column], color='blue', linestyle='--', label=\"Idle\")\n",
    "#         axes[0].set_title(f\"Idle - {column}\", fontsize=12)\n",
    "#         axes[0].set_xlabel(\"Time\", fontsize=10)\n",
    "#         axes[0].set_ylabel(column)\n",
    "#         axes[0].legend()\n",
    "#         axes[0].grid(True)\n",
    "\n",
    "#         # Format x-axis for better readability\n",
    "#         axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "#         axes[0].tick_params(axis='x', rotation=45)\n",
    "          \n",
    "#         # Benchmark (Right Side)\n",
    "#         axes[1].plot(bench_df[\"Timestamp\"], bench_df[column], color='red', linestyle='-', label=\"Benchmark\")\n",
    "#         axes[1].set_title(f\"Benchmark - {column}\")\n",
    "#         axes[1].set_xlabel(\"Time\")\n",
    "#         axes[1].set_ylabel(column)\n",
    "#         axes[1].legend()\n",
    "#         axes[1].grid(True)\n",
    "\n",
    "#         # Format x-axis for better readability\n",
    "#         axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "#         axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "#         # Main figure title\n",
    "#         fig.suptitle(f\"{title_prefix} - {column}\", fontsize=14)\n",
    "        \n",
    "#         plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "#         plt.show()\n",
    "#         plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_graphs(idle_df, bench_df, title_prefix):\n",
    "    \"\"\"\n",
    "    Creates side-by-side subplots for each metric, plotting idle (left) and benchmark (right)\n",
    "    using Seaborn for a more aesthetically pleasing design.\n",
    "    \"\"\"\n",
    "    columns_to_plot = [\n",
    "        \"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \n",
    "        \"(CPUs+GT+SA) Power(W)\", \"Avg Num Cores Active\", \"CPU Temp(C)\"\n",
    "    ]\n",
    "    \n",
    "    # Set Seaborn theme\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "    \n",
    "    for column in columns_to_plot:\n",
    "        # Create side-by-side subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "        # Plot Idle data on the first subplot\n",
    "        sns.lineplot(data=idle_df, x=\"Timestamp\", y=column, label=\"Idle\", color='blue', linestyle='--', ax=axes[0], errorbar=None)\n",
    "        axes[0].set_title(f\"Idle - {column}\", fontsize=12)\n",
    "        axes[0].set_xlabel(\"Time\", fontsize=10)\n",
    "        axes[0].set_ylabel(column, fontsize=10)\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # Format x-axis for better readability\n",
    "        axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Plot Benchmark data on the second subplot\n",
    "        sns.lineplot(data=bench_df, x=\"Timestamp\", y=column, label=\"Benchmark\", color='red', ax=axes[1], errorbar=None)\n",
    "        axes[1].set_title(f\"Benchmark - {column}\", fontsize=12)\n",
    "        axes[1].set_xlabel(\"Time\", fontsize=10)\n",
    "        axes[1].set_ylabel(column, fontsize=10)\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # Format x-axis for better readability\n",
    "        axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Main figure title\n",
    "        fig.suptitle(f\"{title_prefix} - {column}\", fontsize=14)\n",
    "        \n",
    "        # Adjust layout to avoid overlap\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(scala_idle_data_clean_outlier, scala_bench_data_clean_outlier, \"Scala Benchmark - Idle vs Active\")\n",
    "plot_graphs(erlang_idle_data_clean_outlier, erlang_bench_data_clean_outlier, \"Erlang Benchmark - Idle vs Active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Average Power Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_columns = [\"CPU Core Power(W)\", \"GT Power(W)\", \"DRAM Power(W)\", \"(CPUs+GT+SA) Power(W)\",\"CPU Temp(C)\", \"Avg Num Cores Active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_benchmark_metrics(df, metrics_columns):\n",
    "    \"\"\"\n",
    "    Calculates the average power consumption for the specified columns.\n",
    "    \"\"\"\n",
    "    avg_power = df[metrics_columns].mean()\n",
    "    return avg_power\n",
    "\n",
    "scala_idle_avgs = calculate_average_benchmark_metrics(scala_idle_data_clean_outlier, metrics_columns)\n",
    "erlang_idle_avgs = calculate_average_benchmark_metrics(erlang_idle_data_clean_outlier, metrics_columns)\n",
    "\n",
    "scala_bench_avgs = calculate_average_benchmark_metrics(scala_bench_data_clean_outlier, metrics_columns)\n",
    "erlang_bench_avgs = calculate_average_benchmark_metrics(erlang_bench_data_clean_outlier, metrics_columns)\n",
    "\n",
    "scala_net_avgs = np.maximum(scala_bench_avgs - scala_idle_avgs, 0)\n",
    "erlang_net_avgs = np.maximum(erlang_bench_avgs - erlang_idle_avgs, 0)\n",
    "\n",
    "\n",
    "print(\"Net Average Metrics Comparison:\\n\")\n",
    "print(\"Scala Benchmark:\")\n",
    "print(scala_net_avgs, \"\\n\")\n",
    "print(\"Erlang Benchmark:\")\n",
    "print(erlang_net_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Energy Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_columns = [\"CPU Core Energy(J)\", \"GT Energy(J)\", \"DRAM Energy(J)\", \"(CPUs+GT+SA) Energy(J)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_net_energy(df, energy_columns):\n",
    "    \"\"\"\n",
    "    Calculates the net energy consumption by subtracting idle energy from benchmark energy.\n",
    "    \"\"\"\n",
    "    avg_energy = df[energy_columns].mean()\n",
    "\n",
    "    return avg_energy\n",
    "\n",
    "scala_idle_avg_energy = calculate_average_benchmark_metrics(scala_idle_data_clean_outlier, energy_columns)\n",
    "erlang_idle_avg_energy = calculate_average_benchmark_metrics(erlang_idle_data_clean_outlier, energy_columns)\n",
    "\n",
    "scala_bench_avg_energy = calculate_average_benchmark_metrics(scala_bench_data_clean_outlier, energy_columns)\n",
    "erlang_bench_avg_energy = calculate_average_benchmark_metrics(erlang_bench_data_clean_outlier, energy_columns)\n",
    "\n",
    "scala_net_avg_energy = np.maximum(scala_bench_avg_energy - scala_idle_avg_energy, 0)\n",
    "erlang_net_avg_energy = np.maximum(erlang_bench_avg_energy - erlang_idle_avg_energy, 0)\n",
    "\n",
    "\n",
    "print(\"Net Average Energy (Joules) Comparison:\\n\")\n",
    "print(\"Scala Benchmark:\")\n",
    "print(scala_net_avg_energy, \"\\n\")\n",
    "print(\"Erlang Benchmark:\")\n",
    "print(erlang_net_avg_energy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
